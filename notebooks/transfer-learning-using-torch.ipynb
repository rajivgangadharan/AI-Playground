{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fdc6d0-f845-49f6-948f-898f27f1b05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers langchain torch \n",
    "!pip install sentence-transformers\n",
    "!pip install langchain-huggingface\n",
    "!pip install -r ../requirements.txt\n",
    "!pip freeze > ../requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "7b59f133-9ad2-44b9-9145-1b6e3320c6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import langchain # No reason why not to use langchain\n",
    "from transformers import BertTokenizer, BertModel, BertForSequenceClassification, AdamW\n",
    "# AdamW is an optimization algorithm used for better performance,  correct weight decay\n",
    "# better generalization (avoiding overfitting)\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "# I have used cohere for embeddings before, now using HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "42762be0-4d3a-44e8-9628-e99d8aa3370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Dataset\n",
    "texts = [\"I am a cool guy\", \n",
    "         \"AI will change this world\", \n",
    "         \"I hate phone scams\",\n",
    "         \"I love cheerful people\",\n",
    "         \"I love friendly people\",\n",
    "         \"I hate rude people\",\n",
    "        ]\n",
    "labels = [1, 1, 0, 1, 1, 0]  # 1: positive, 0: negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "70594ca9-ddfc-4e2c-9231-d060f9dd35d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer and Model\n",
    "# using this model https://huggingface.co/google-bert/bert-base-uncased \n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "# model = BertModel.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "064adcc7-5286-473a-bddb-535f12b182f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the inputs\n",
    "max_len = 128\n",
    "encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n",
    "output = model(**encodings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "5d136418-e987-4642-83a0-a60b127493e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split\n",
    "train_texts, validation_texts, train_labels, validation_labels = train_test_split(texts, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "0faf08d0-29f2-492f-856b-61f40e01f6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing the inputs for the training set\n",
    "train_encodings = tokenizer(train_texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n",
    "validation_encodings = tokenizer(validation_texts, padding=True, truncation=True, max_length=max_len, return_tensors='pt')\n",
    "\n",
    "# Create tensors for input ids, attention masks, and labels\n",
    "train_input_ids = train_encodings['input_ids']\n",
    "train_attention_masks = train_encodings['attention_mask']\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "\n",
    "validation_input_ids = validation_encodings['input_ids']\n",
    "validation_attention_masks = validation_encodings['attention_mask']\n",
    "validation_labels_tensor = torch.tensor(validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "4baf2379-e477-46c6-9f76-1dc1f67a8767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traning\n",
      "Input IDs: tensor([[  101,  1045,  2293, 18350,  2111,   102,     0],\n",
      "        [  101,  1045,  2293,  5379,  2111,   102,     0],\n",
      "        [  101,  1045,  5223, 12726,  2111,   102,     0],\n",
      "        [  101,  1045,  5223,  3042,  8040, 13596,   102]])\n",
      "Attention Masks: tensor([[1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1]])\n",
      "Labels: tensor([1, 1, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "# Check the tensors\n",
    "print(\"Traning\")\n",
    "print(f\"Input IDs: {train_input_ids}\")\n",
    "print(f\"Attention Masks: {train_attention_masks}\")\n",
    "print(f\"Labels: {train_labels_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "3a1c45f3-4c47-44f7-aabf-b8a076550beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation\n",
      "Input IDs: tensor([[ 101, 1045, 2572, 1037, 4658, 3124,  102],\n",
      "        [ 101, 9932, 2097, 2689, 2023, 2088,  102]])\n",
      "Attention Masks: tensor([[1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1]])\n",
      "Labels: tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Check the tensors\n",
    "print(\"Validation\")\n",
    "print(f\"Input IDs: {validation_input_ids}\")\n",
    "print(f\"Attention Masks: {validation_attention_masks}\")\n",
    "print(f\"Labels: {validation_labels_tensor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "14fc4f42-9b1a-446f-837d-bd04a5c0466b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "8a79a8d4-a9e5-416c-bd9c-b067bf4445f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "input_ids = input_ids.to(device)\n",
    "attention_masks = attention_masks.to(device)\n",
    "#labels_tensor = labels_tensor.to(device) # Not needed for BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "e62c984c-df5d-4977-a9e6-468b26712eec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/13\n",
      "Loss: 0.656816840171814\n",
      "Epoch 2/13\n",
      "Loss: 0.7356657981872559\n",
      "Epoch 3/13\n",
      "Loss: 0.737143337726593\n",
      "Epoch 4/13\n",
      "Loss: 0.7125605940818787\n",
      "Epoch 5/13\n",
      "Loss: 0.6921197772026062\n",
      "Epoch 6/13\n",
      "Loss: 0.6855766773223877\n",
      "Epoch 7/13\n",
      "Loss: 0.6678639650344849\n",
      "Epoch 8/13\n",
      "Loss: 0.69581139087677\n",
      "Epoch 9/13\n",
      "Loss: 0.6950128674507141\n",
      "Epoch 10/13\n",
      "Loss: 0.7002564072608948\n",
      "Epoch 11/13\n",
      "Loss: 0.709318220615387\n",
      "Epoch 12/13\n",
      "Loss: 0.7273451685905457\n",
      "Epoch 13/13\n",
      "Loss: 0.762508749961853\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "model.train()  # Set the model to training mode\n",
    "epochs = 13  # Define the number of epochs\n",
    "loss_fn = torch.nn.CrossEntropyLoss()  # Define loss function\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    \n",
    "    # Forward pass\n",
    "    optimizer.zero_grad()  # Clear previous gradients\n",
    "    logits = model(input_ids=train_input_ids.to(device), attention_mask=train_attention_masks.to(device), labels=train_labels_tensor.to(device)).logits\n",
    "    \n",
    "    # Calculate loss\n",
    "    loss = loss_fn(logits, train_labels_tensor.to(device))  # Actual loss calculation\n",
    "\n",
    "    # Backward pass\n",
    "    loss.backward()  # Calculate gradients\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    print(f\"Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "7f12448d-9255-458e-9265-646b9bc85434",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./fine_tuned_bert/tokenizer_config.json',\n",
       " './fine_tuned_bert/special_tokens_map.json',\n",
       " './fine_tuned_bert/vocab.txt',\n",
       " './fine_tuned_bert/added_tokens.json')"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model if needed\n",
    "model.save_pretrained(\"./fine_tuned_bert\")\n",
    "tokenizer.save_pretrained(\"./fine_tuned_bert\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fed8d7b2-56e5-45c5-8e9e-cb5c457a0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the fine-tuned model with LangChain\n",
    "hf_embedding = HuggingFaceEmbeddings(model_name=\"./fine_tuned_bert\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "18a1afbe-66e6-4422-9a66-65cba6ba72f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence Embedding: [0.34589746594429016, 0.36306294798851013, 0.0735308825969696, 0.17232845723628998, 0.25641950964927673, -0.6112189292907715, 0.18540552258491516, 0.6184269785881042, 0.028799623250961304, -0.3970279097557068, 0.06879080832004547, -0.38036468625068665, 0.2705947756767273, 0.4087296426296234, -0.11404649913311005, -0.05419629067182541, 0.06095239520072937, 0.056249797344207764, 0.13045738637447357, 0.2099624127149582, -0.13728414475917816, -0.0386010967195034, 0.0044868155382573605, 0.5139421820640564, 0.3674030900001526, -0.05744873732328415, -0.09730406105518341, 0.03610280528664589, -0.13072578608989716, -0.33737850189208984, 0.24164095520973206, 0.19513057172298431, 0.016824020072817802, 0.0882086306810379, -0.4711914658546448, -0.26859337091445923, -0.3821861445903778, -0.2459501475095749, -0.3571707606315613, -0.1687784492969513, -0.18893380463123322, -0.10749228298664093, -0.030550247058272362, -0.28504541516304016, 0.22028732299804688, -0.2861773669719696, -0.46710020303726196, -0.09920758008956909, 0.4183298945426941, -0.3140581548213959, -0.5407671928405762, 0.3922024071216583, -0.18805184960365295, -0.04624948650598526, 0.2082795649766922, 0.2978772521018982, -0.18409331142902374, -0.7103412747383118, -0.0701403021812439, 0.042826928198337555, 0.12230332940816879, 0.19521677494049072, -0.08378050476312637, -0.20997348427772522, 0.38677918910980225, -0.024628257378935814, -0.22867174446582794, 0.0667773187160492, -0.6370210647583008, -0.2347634732723236, -0.310682475566864, -0.14981500804424286, 0.30303236842155457, -0.3856963515281677, -0.04925401881337166, 0.3947550654411316, -0.1710004061460495, 0.08331064134836197, 0.054878901690244675, 0.1281554400920868, -0.21774423122406006, 0.8699490427970886, -0.12510055303573608, 0.28456607460975647, 0.32164648175239563, 0.1961994618177414, -0.2093251645565033, 0.05474044010043144, 0.11284933984279633, 0.09446850419044495, -0.28852003812789917, -0.056581396609544754, -0.023026078939437866, 0.27253857254981995, 0.6661616563796997, 0.016955748200416565, -0.01307951845228672, -0.08487338572740555, -0.32579296827316284, 0.40203404426574707, -0.050942085683345795, -0.35054439306259155, 0.0826418548822403, 0.20215058326721191, 0.2169504165649414, 0.14417847990989685, 0.15510834753513336, -0.17869454622268677, 0.10244259983301163, -0.08484798669815063, 0.01142928283661604, -0.17024382948875427, 0.032478541135787964, -0.2005082368850708, -0.2327769696712494, 0.19759541749954224, 0.34342479705810547, 0.1640016734600067, 0.005704599432647228, 0.24813850224018097, -0.29064708948135376, 0.1421918421983719, 0.29973024129867554, 0.832194983959198, -0.37398257851600647, -0.0019060068298131227, -0.05212376266717911, -0.09846046566963196, -0.08407317101955414, -0.39337486028671265, 0.3016778826713562, 0.4124378561973572, 0.6549603939056396, -0.33940207958221436, -0.2547621428966522, 0.4872671961784363, -0.012431121431291103, -0.37692779302597046, -0.47583872079849243, 0.2292749583721161, -0.0008453354239463806, 0.13587629795074463, 0.17020931839942932, 0.06693236529827118, 0.2216421663761139, 0.37541985511779785, 0.05916403979063034, 0.3192515969276428, 0.09163837134838104, 0.19540078938007355, 0.2990620732307434, 0.24562017619609833, -0.4740803837776184, -0.46501556038856506, -0.1311752200126648, 0.17969343066215515, -0.6374809145927429, 0.43840011954307556, 0.4532567858695984, -0.027415787801146507, -0.09157736599445343, -0.261068195104599, -0.16829773783683777, 0.10571715980768204, -0.324094295501709, 0.11066502332687378, 0.05132467299699783, 0.3068811297416687, -0.05989031866192818, 0.07863932847976685, -0.3419864773750305, 0.1611543446779251, 0.6911599040031433, -0.08722219616174698, -0.30653131008148193, -0.1080184355378151, 0.06244785338640213, 0.2688199579715729, 0.12250306457281113, -0.004085326101630926, -2.019376277923584, -0.23579831421375275, 0.28106898069381714, -0.16295203566551208, 0.11226071417331696, -0.36282095313072205, 0.20734071731567383, -0.6256195306777954, -0.10386037826538086, 0.23756973445415497, -0.3354385495185852, -0.047013018280267715, -0.031514544039964676, -0.05918582156300545, 0.6783453822135925, -0.2059076726436615, -0.012371708638966084, -0.18579533696174622, -0.06175168603658676, -0.09020614624023438, 0.03366265073418617, -0.21551212668418884, -0.048049475997686386, 0.27319905161857605, -0.3103492856025696, 0.0802004337310791, -0.08189807087182999, 0.01923934742808342, -0.3007526695728302, -0.29072025418281555, -0.48651322722435, 0.5443631410598755, -0.08603908121585846, -0.037776879966259, -0.14533494412899017, -0.1422867476940155, 0.12981274724006653, 0.015569781884551048, -0.24040932953357697, -0.021609697490930557, 0.05234387516975403, -0.27928027510643005, -0.5393097400665283, 0.5029295682907104, 0.05666600912809372, 0.2097037136554718, -0.015857668593525887, 0.19118234515190125, 0.34337741136550903, 0.5392252802848816, -0.23650245368480682, -0.3290766477584839, 0.3899970054626465, 0.054468609392642975, -0.08400728553533554, -0.013132201507687569, -0.22522346675395966, -0.3001333475112915, 0.09479773044586182, 0.01652488112449646, -0.4693641662597656, 0.24715213477611542, -0.12753459811210632, 0.3298138976097107, 0.2555428147315979, 0.010653624311089516, -0.09903338551521301, 0.22821708023548126, 0.16759827733039856, -0.2675628066062927, -0.1777852177619934, -0.46487680077552795, 0.2145463526248932, -0.28489142656326294, 0.013643210753798485, -0.08411135524511337, -0.15562278032302856, 0.233830526471138, -0.20589151978492737, 0.3416665196418762, 0.2896520793437958, 0.303432434797287, 0.4302133023738861, -0.04555101320147514, -0.33238497376441956, -0.6765086650848389, 0.11773721128702164, 0.023805389180779457, 0.22564145922660828, -0.013792094774544239, -0.2132478505373001, -0.5585734844207764, 0.18028950691223145, -0.07948033511638641, -0.6500422358512878, -0.2901223301887512, 0.011029073968529701, -0.06218694895505905, 0.2057642638683319, -0.16866299510002136, -0.12065398693084717, 0.48350486159324646, -0.6544708013534546, 0.2934853434562683, 0.13508516550064087, 0.02256510779261589, -0.1029990166425705, -0.14026834070682526, -0.006525896489620209, -0.4073704779148102, -0.12239768356084824, 0.1476275622844696, -0.3391510546207428, 0.03061930276453495, 0.3013399541378021, 0.10174544155597687, 0.2971625328063965, -0.20657138526439667, 0.17052970826625824, -0.0963788628578186, -0.08419739454984665, -0.3114154636859894, 0.1648944765329361, 0.15586614608764648, -0.22684407234191895, 0.2553475797176361, -0.20866134762763977, -0.24117843806743622, -3.123137950897217, -0.03416740521788597, -0.058709096163511276, 0.06486836075782776, 0.2815467119216919, 0.03055698610842228, -0.23552298545837402, 0.12384402751922607, -0.5001667737960815, -0.03567938879132271, -0.05151458829641342, 0.06416550278663635, 0.26838916540145874, 0.18494534492492676, -0.19151555001735687, 0.4872160851955414, 0.12983253598213196, -0.09467986971139908, -0.13990971446037292, 0.5214704275131226, -0.1692991852760315, 0.01878025196492672, -0.05684850364923477, 0.15340033173561096, 0.44504767656326294, -0.27532169222831726, -0.48280787467956543, 0.21935871243476868, -0.24756309390068054, 0.04681020602583885, -0.023273440077900887, -0.44038844108581543, 0.027643930166959763, 0.15328001976013184, 0.0810011774301529, 0.012313122861087322, 0.0512252151966095, 0.08182306587696075, 0.058616310358047485, 0.03168318048119545, 0.3538911044597626, -0.22539730370044708, 0.11633354425430298, -0.09189571440219879, 0.4872494339942932, -0.3415239453315735, 0.02969854511320591, -0.05532913655042648, 0.11807509511709213, 0.12801142036914825, 0.07112181931734085, -0.1672426164150238, 0.2690224051475525, -0.014910641126334667, -0.2183101922273636, -0.4264361262321472, 0.5715356469154358, 0.6019390225410461, -0.22170105576515198, -0.007163467817008495, 0.2971412241458893, -0.3829041123390198, -0.2548077702522278, -0.11755260080099106, -0.03420085459947586, -0.42093008756637573, -0.6678290367126465, -0.45943936705589294, -0.15613654255867004, -0.11695960909128189, 0.11188922077417374, 0.17888741195201874, -0.18028570711612701, -0.8654972314834595, 0.1665835827589035, 0.10957896709442139, -0.04458029940724373, 0.06898722052574158, 0.1324102133512497, 0.2395990788936615, -0.41873854398727417, -0.717802882194519, -0.062272150069475174, 0.11426490545272827, 0.0793401226401329, -0.2788854241371155, -0.41377314925193787, -0.026807764545083046, -0.04546155408024788, -0.28768390417099, 0.31986695528030396, 0.07951120287179947, 0.16494034230709076, 0.23967833817005157, 0.19227218627929688, -0.06500880420207977, 0.23427589237689972, -0.3268871009349823, 0.16176816821098328, 0.2641988694667816, 0.1866203248500824, 0.036909155547618866, -0.0074793873354792595, 0.30348461866378784, 0.10723312199115753, 0.5093114376068115, -0.2550986111164093, 0.03570530191063881, 0.23540422320365906, 0.33539503812789917, 0.011969894170761108, -0.14955338835716248, 0.26480764150619507, -0.10357600450515747, -0.18813872337341309, -0.021496403962373734, 0.07023946195840836, 0.40655478835105896, -0.013231170363724232, -0.16352157294750214, -0.10235937684774399, 0.2222960740327835, -0.2210228145122528, 0.21126285195350647, 0.02871640957891941, -0.26371946930885315, -0.30084261298179626, -0.0671258419752121, -0.28173917531967163, -0.0013459859183058143, 0.30401578545570374, -0.03665341064333916, -0.15520599484443665, 0.17952582240104675, -0.13790857791900635, -0.12398971617221832, -0.06383059918880463, 0.12508931756019592, 0.06425510346889496, -0.23466625809669495, 0.20603540539741516, 0.4650883078575134, -0.0243348591029644, 0.16446810960769653, 0.023110676556825638, 0.27856290340423584, -0.26405420899391174, 0.034044526517391205, -0.21601799130439758, -0.005752826575189829, 0.08826257288455963, -0.19228219985961914, -0.20863962173461914, -0.2683584690093994, 0.16317394375801086, 0.033438168466091156, 0.16998329758644104, -0.2048313170671463, 0.13451793789863586, -0.28084391355514526, 0.2413061112165451, 0.27325892448425293, -0.0045486269518733025, 0.18831433355808258, -0.07379300892353058, 0.4383925497531891, 0.03554896265268326, -0.2575954794883728, -0.04168374091386795, 0.03554361313581467, -0.08524205535650253, -0.28629183769226074, -0.07058186829090118, -0.4965253472328186, -0.07074330747127533, 0.2953007221221924, -0.02509828843176365, -0.36804163455963135, -0.09739425033330917, 0.03289508447051048, -0.09576594829559326, -0.5642791986465454, -0.1328476369380951, -0.1070931926369667, 0.20716755092144012, 0.2705930769443512, 0.11344113200902939, 0.0491720512509346, 0.11400008201599121, -0.02476941980421543, -0.38267892599105835, 0.2772412896156311, -0.45364922285079956, -0.08642508834600449, -0.8620330691337585, -0.4301552176475525, 0.4134076237678528, -0.07803080976009369, 0.3569858968257904, 0.1546066403388977, 0.27514058351516724, 0.11287020146846771, -0.2800261676311493, 0.004874157719314098, 0.097234345972538, -0.19638700783252716, -0.014944138005375862, -0.03182698413729668, -0.06636369228363037, 0.07082094997167587, -0.47604888677597046, -0.6445785164833069, 0.033541787415742874, -0.2753518521785736, 0.3181696832180023, -0.0890267863869667, 0.24047568440437317, -0.1946680098772049, -0.27716749906539917, 0.14183419942855835, -0.35668930411338806, 0.008349543437361717, 0.12082024663686752, 0.03840095177292824, -0.45279914140701294, -0.27298831939697266, -0.17168454825878143, -0.023250574246048927, -0.5717905163764954, 0.06835059076547623, -0.08051582425832748, -0.12969335913658142, 0.28367191553115845, 0.09516198188066483, -0.02799142338335514, 0.09110379964113235, -0.0610489621758461, 0.21472902595996857, 0.41545623540878296, -0.3483272194862366, 0.0683654397726059, -0.266288161277771, -0.21055087447166443, 0.3768189549446106, 0.04486589878797531, -0.48258957266807556, -0.40142208337783813, 0.4486742913722992, -0.28900355100631714, -0.10320527851581573, -0.10973616689443588, -0.2051316797733307, -0.2698400914669037, -0.05456187203526497, -0.09886584430932999, -0.43644165992736816, -0.1696072816848755, -0.0763276070356369, -0.11866281181573868, 0.10107465088367462, -0.01872977428138256, -0.002321103122085333, -0.07788589596748352, 0.45978695154190063, 0.023309340700507164, 0.29022178053855896, 0.1652202308177948, 0.022431161254644394, -0.08943002671003342, -0.3279460668563843, -0.41464510560035706, -0.1026458591222763, 0.10014643520116806, -0.001250237226486206, -0.3083461821079254, -0.13518908619880676, 0.14148668944835663, -0.5036582350730896, 0.015769734978675842, -0.5927183628082275, 0.16076278686523438, 0.22269153594970703, 0.1619386225938797, -0.36341190338134766, 0.15801092982292175, 0.03390470892190933, -0.23212453722953796, 0.13149923086166382, -0.011269655078649521, -0.017847800627350807, 0.1340053677558899, 0.36663350462913513, -0.2218267023563385, 0.37468597292900085, -0.13376016914844513, -0.016296381130814552, 0.36277300119400024, -0.15161249041557312, 0.05634565278887749, 0.13931399583816528, -0.13390643894672394, 0.7376760244369507, 0.6079232096672058, -0.032112449407577515, -0.26176610589027405, 0.27961990237236023, 0.19658663868904114, 0.15749965608119965, 0.25833553075790405, 0.2940656542778015, -0.4287794530391693, -0.19843026995658875, 0.4691731929779053, 0.5762017965316772, -0.6903340816497803, -0.33086255192756653, 0.3229007124900818, -0.1981980949640274, 0.12440332025289536, 0.39005517959594727, 0.07570558786392212, -0.22208423912525177, 0.2007131576538086, -0.26163166761398315, -0.1691175401210785, 0.3781164586544037, -0.24061580002307892, -0.41939154267311096, 0.052284449338912964, 0.27220210433006287, 0.03131358325481415, 0.17753960192203522, -0.21852335333824158, 0.48132044076919556, 0.45246800780296326, -0.12988033890724182, 0.2031393051147461, 0.32109636068344116, 0.2530662715435028, 0.046833474189043045, 0.10404285043478012, -0.14740249514579773, 0.08978395909070969, 0.670275866985321, 0.00205114483833313, 0.03994838520884514, 0.18029442429542542, 0.1797514408826828, 0.44447359442710876, -0.05581173300743103, 0.11877506971359253, 0.369877427816391, -0.08706366270780563, -0.43413177132606506, 0.10927563905715942, -0.139835923910141, 0.7890467047691345, 0.07140214741230011, 0.09143120050430298, -0.2614426016807556, 0.2804252505302429, -0.15194353461265564, 0.05081399157643318, -0.4649481177330017, 0.3023131191730499, 0.5264685153961182, 0.4789763391017914, -0.4483049511909485, -0.17478275299072266, 0.22776329517364502, -0.031053874641656876, 0.23868601024150848, 0.10285991430282593, -0.18210165202617645, -0.06173878163099289, 0.6485994458198547, -0.009347518905997276, -0.2495778501033783, 0.021547693759202957, -0.14901752769947052, 0.09532621502876282, 0.07939822971820831, -0.3049468398094177, -0.23913569748401642, -0.28772029280662537, -0.4971187710762024, 0.10160984843969345, -0.11525193601846695, -0.00866993423551321, -0.34780293703079224, 0.06937011331319809, -0.12907171249389648, 0.2534811496734619, -0.5307604074478149, 0.3946361541748047, -0.22836124897003174, 0.2204817235469818, 0.33506157994270325, 0.4541257917881012, 0.19224803149700165, 0.1707613468170166, -0.0532110221683979, -0.19717147946357727, 0.20942524075508118, -0.23092572391033173, 0.4024538993835449, 0.07674096524715424, -0.17945890128612518, -0.07103588432073593, -0.43992775678634644, 0.5113129615783691, 0.4515344202518463, -0.8689753413200378, -0.19848421216011047, -0.22201624512672424, 0.22292399406433105, 0.14827963709831238, 0.028725191950798035, -0.14525391161441803, 0.16291746497154236, 0.019671408459544182, -0.11283808946609497, 0.12793181836605072, 0.48208922147750854, -0.15288731455802917, 0.6493744254112244, -0.08186327666044235, 0.06745028495788574, -0.01569708064198494, -0.18934401869773865, -0.20215435326099396, 0.3235440254211426, -0.30236417055130005, 0.2626079022884369, 0.2647533416748047, -0.27171558141708374, -0.3443688750267029, 0.014323192648589611, -0.12313206493854523, -0.3250828683376312, -0.09964339435100555, 0.21010319888591766, 0.06101356819272041, -0.20489783585071564, -0.9911397099494934, 0.262040376663208, 0.07845338433980942, -0.2429477870464325, -0.09868744015693665, -0.44434690475463867, 0.005958059336990118, -0.0621756911277771, -0.051294825971126556, -0.25986653566360474, 0.3423506021499634, 0.10496510565280914, 0.030981456860899925, -0.010147357359528542, -0.023028716444969177, 0.17249174416065216]\n"
     ]
    }
   ],
   "source": [
    "# Example sentence embeddings with LangChain\n",
    "sentence = \"I love using BERT for transfer learning.\"\n",
    "embedding = hf_embedding.embed_query(sentence)\n",
    "print(\"Sentence Embedding:\", embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4275cee9-936e-4587-86b4-788609cc8bc1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
